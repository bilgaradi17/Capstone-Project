{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f308f99",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "The objective of this project is to develop a machine learning model that can accurately detect and classify diseases in rice plant leaves. Rice is one of the most important staple crops globally, and diseases can significantly impact its yield and quality. Early and accurate detection of diseases in rice plants can enable timely intervention and effective disease management strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d72eb4",
   "metadata": {},
   "source": [
    "### Key challenges:\n",
    "\n",
    "Multi-class Classification: The model should be able to classify rice leaf images into multiple disease categories, such as Brown Spot, Leaf Smut, and Bacterial Leaf Blight. Each disease has distinct visual symptoms and patterns that need to be learned by the model.\n",
    "\n",
    "Real-time Detection: The model should be capable of real-time disease detection in rice plant leaves. It should be able to process images quickly and provide accurate predictions, allowing farmers or agricultural experts to take prompt actions based on the results.\n",
    "\n",
    "Generalization to New Samples: The trained model should have good generalization capabilities and be able to detect diseases accurately on unseen images. It should be robust to variations in lighting conditions, image quality, and different rice leaf varieties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a5b2bb",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "Preprocess the dataset by resizing, normalizing, and augmenting the images to enhance the model's ability to learn and generalize.\n",
    "\n",
    "Model Selection and Architecture Design: Choose an appropriate pre-trained model or design a custom architecture suitable for the rice leaf disease detection task. The model should have sufficient capacity to capture the complex patterns associated with different diseases.\n",
    "\n",
    "Transfer Learning and Fine-tuning: Utilize transfer learning by leveraging pre-trained models trained on large-scale image datasets. Fine-tune the selected model on the rice leaf disease dataset to adapt it to the specific task and disease classes.\n",
    "\n",
    "Model Training and Evaluation: Split the dataset into training and validation sets. Train the model using the training set and optimize its performance using appropriate loss functions, optimizers, and learning rate schedules. Evaluate the model's performance on the validation set using appropriate evaluation metrics such as accuracy, precision, recall, and F1-score.\n",
    "\n",
    "Hyperparameter Tuning: Fine-tune hyperparameters such as learning rate, batch size, regularization techniques, and model architecture to optimize the model's performance and improve its accuracy.\n",
    "\n",
    "Real-time Deployment: Once the model achieves satisfactory performance on the validation set, deploy it to a real-time environment where it can process incoming rice leaf images and provide disease predictions in real-time.\n",
    "### Target \n",
    "By developing an accurate and efficient rice leaf disease detection model, this project aims to assist farmers and agricultural experts in detecting diseases early, implementing timely interventions, and effectively managing rice plant health, leading to improved crop yields and reduced economic losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0d326d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e9f1d043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Preparation\n",
    "data_dir = r'C:\\\\Users\\\\bdiko\\\\Downloads\\\\PRCP-1001-RiceLeaf-10\\\\Data\\\\'\n",
    "class_names = ['Bacterial leaf blight', 'Brown spot', 'Leaf smut']\n",
    "image_size = (224, 224)  # Adjust the size according to your requirements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d64315a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bacterial leaf blight', 'Brown spot', 'Leaf smut']\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'C:\\\\Users\\\\bdiko\\\\Downloads\\\\PRCP-1001-RiceLeaf-10\\\\Data\\\\'\n",
    "print(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "218985cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Data Preprocessing\n",
    "def preprocess_images(image_paths):\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        img = Image.open(path)\n",
    "        img = img.resize(image_size)\n",
    "        img = np.array(img) / 255.0  # Normalize pixel values\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for class_name in class_names:\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    image_paths = [os.path.join(class_dir, img) for img in os.listdir(class_dir) if img.endswith('.jpg')]\n",
    "    labels = [class_names.index(class_name)] * len(image_paths)\n",
    "    X.extend(image_paths)\n",
    "    y.extend(labels)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = preprocess_images(X_train)\n",
    "X_test = preprocess_images(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3f499dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_train and y_test to numpy arrays\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "68a65929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Model Development\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(image_size[0], image_size[1], 3))\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(class_names), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "88d5d684",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 19s 5s/step - loss: 10.2007 - accuracy: 0.4878 - val_loss: 1.0885 - val_accuracy: 0.3636\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 18s 5s/step - loss: 0.9998 - accuracy: 0.5366 - val_loss: 1.9661 - val_accuracy: 0.4545\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 18s 14s/step - loss: 1.6331 - accuracy: 0.4878 - val_loss: 1.0555 - val_accuracy: 0.3636\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 18s 5s/step - loss: 1.1630 - accuracy: 0.2927 - val_loss: 1.0616 - val_accuracy: 0.4545\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 18s 5s/step - loss: 0.8914 - accuracy: 0.6098 - val_loss: 1.1523 - val_accuracy: 0.4545\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 18s 5s/step - loss: 1.0797 - accuracy: 0.5854 - val_loss: 1.1587 - val_accuracy: 0.3636\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 18s 5s/step - loss: 1.1093 - accuracy: 0.5122 - val_loss: 1.1067 - val_accuracy: 0.3636\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 18s 5s/step - loss: 1.0412 - accuracy: 0.4146 - val_loss: 1.1075 - val_accuracy: 0.3636\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 18s 5s/step - loss: 1.0366 - accuracy: 0.4878 - val_loss: 1.1002 - val_accuracy: 0.3636\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 20s 5s/step - loss: 0.9642 - accuracy: 0.3659 - val_loss: 1.0786 - val_accuracy: 0.3636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2000aee3fa0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Model Training\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "train_datagen = ImageDataGenerator(rotation_range=20, width_shift_range=0.2, height_shift_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "\n",
    "model.fit(train_generator, epochs=epochs, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "43e5d351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 1.0786 - accuracy: 0.3636\n",
      "Test Loss: 1.0786045789718628\n",
      "Test Accuracy: 0.3636363744735718\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Model Evaluation\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0dc43ab3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 528ms/step\n",
      "Image: [[[1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  ...\n",
      "  [0.86666667 0.85490196 0.21176471]\n",
      "  [0.87058824 0.85882353 0.23529412]\n",
      "  [0.86666667 0.85490196 0.24705882]]\n",
      "\n",
      " [[1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  ...\n",
      "  [0.85490196 0.84313725 0.2       ]\n",
      "  [0.85882353 0.84705882 0.22352941]\n",
      "  [0.85490196 0.84313725 0.23529412]]\n",
      "\n",
      " [[1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  ...\n",
      "  [0.82745098 0.81568627 0.16470588]\n",
      "  [0.83137255 0.81960784 0.19215686]\n",
      "  [0.82745098 0.81568627 0.2       ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.76862745 0.59607843 0.25490196]\n",
      "  [0.78039216 0.60392157 0.26666667]\n",
      "  [0.78823529 0.61568627 0.27058824]\n",
      "  ...\n",
      "  [0.4        0.39607843 0.01176471]\n",
      "  [0.40784314 0.40392157 0.01960784]\n",
      "  [0.41960784 0.40392157 0.02352941]]\n",
      "\n",
      " [[0.74901961 0.58431373 0.24313725]\n",
      "  [0.76078431 0.58823529 0.25490196]\n",
      "  [0.77254902 0.6        0.25882353]\n",
      "  ...\n",
      "  [0.39215686 0.39607843 0.01960784]\n",
      "  [0.40392157 0.40392157 0.02352941]\n",
      "  [0.42352941 0.41568627 0.03137255]]\n",
      "\n",
      " [[0.74117647 0.57647059 0.23921569]\n",
      "  [0.75294118 0.58039216 0.24705882]\n",
      "  [0.76470588 0.59215686 0.25490196]\n",
      "  ...\n",
      "  [0.39215686 0.39607843 0.01960784]\n",
      "  [0.40392157 0.40392157 0.02352941]\n",
      "  [0.42352941 0.41568627 0.03137255]]] - Predicted Class: Brown spot\n",
      "Image: [[[1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  ...\n",
      "  [1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  [0.99607843 0.99607843 0.99607843]]\n",
      "\n",
      " [[1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  ...\n",
      "  [1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  [0.99607843 0.99607843 0.99607843]]\n",
      "\n",
      " [[1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  ...\n",
      "  [1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  [0.99607843 0.99607843 0.99607843]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.96470588 0.96470588 0.96470588]\n",
      "  [0.95686275 0.95686275 0.95686275]\n",
      "  [0.96470588 0.96470588 0.96470588]\n",
      "  ...\n",
      "  [1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]]\n",
      "\n",
      " [[0.96470588 0.96470588 0.96470588]\n",
      "  [0.95686275 0.95686275 0.95686275]\n",
      "  [0.96862745 0.96862745 0.96862745]\n",
      "  ...\n",
      "  [1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]]\n",
      "\n",
      " [[0.96470588 0.96470588 0.96470588]\n",
      "  [0.95686275 0.95686275 0.95686275]\n",
      "  [0.96862745 0.96862745 0.96862745]\n",
      "  ...\n",
      "  [0.99607843 0.99607843 0.99607843]\n",
      "  [1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]]] - Predicted Class: Brown spot\n",
      "Image: [[[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]] - Predicted Class: Brown spot\n",
      "Image: [[[0.70196078 0.84705882 0.25098039]\n",
      "  [0.72941176 0.87843137 0.22745098]\n",
      "  [0.72941176 0.89019608 0.22745098]\n",
      "  ...\n",
      "  [0.60784314 0.80784314 0.12941176]\n",
      "  [0.60784314 0.79607843 0.12156863]\n",
      "  [0.61176471 0.78431373 0.12156863]]\n",
      "\n",
      " [[0.61176471 0.77254902 0.16078431]\n",
      "  [0.63137255 0.79215686 0.1372549 ]\n",
      "  [0.63921569 0.81176471 0.14117647]\n",
      "  ...\n",
      "  [0.62745098 0.82352941 0.15294118]\n",
      "  [0.62745098 0.81568627 0.15294118]\n",
      "  [0.62352941 0.79607843 0.1372549 ]]\n",
      "\n",
      " [[0.62745098 0.80784314 0.17254902]\n",
      "  [0.64705882 0.82352941 0.15294118]\n",
      "  [0.65490196 0.83921569 0.15686275]\n",
      "  ...\n",
      "  [0.65882353 0.85098039 0.19215686]\n",
      "  [0.65490196 0.83529412 0.18431373]\n",
      "  [0.65490196 0.82745098 0.17647059]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  ...\n",
      "  [1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]]\n",
      "\n",
      " [[1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  ...\n",
      "  [1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]]\n",
      "\n",
      " [[1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  ...\n",
      "  [1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]]] - Predicted Class: Brown spot\n",
      "Image: [[[0.96470588 0.96470588 0.96470588]\n",
      "  [0.9372549  0.9372549  0.9372549 ]\n",
      "  [0.95294118 0.95294118 0.95294118]\n",
      "  ...\n",
      "  [0.97254902 0.97254902 0.97254902]\n",
      "  [0.97254902 0.97254902 0.97254902]\n",
      "  [0.96862745 0.96862745 0.96078431]]\n",
      "\n",
      " [[0.96862745 0.96862745 0.96862745]\n",
      "  [0.95294118 0.95294118 0.95294118]\n",
      "  [0.95686275 0.95686275 0.95686275]\n",
      "  ...\n",
      "  [0.97254902 0.97254902 0.97254902]\n",
      "  [0.97254902 0.97254902 0.97254902]\n",
      "  [0.96862745 0.96862745 0.96470588]]\n",
      "\n",
      " [[0.96862745 0.96862745 0.96862745]\n",
      "  [0.96470588 0.96470588 0.96470588]\n",
      "  [0.96862745 0.96862745 0.96862745]\n",
      "  ...\n",
      "  [0.96862745 0.96862745 0.96862745]\n",
      "  [0.96862745 0.96862745 0.96862745]\n",
      "  [0.96862745 0.96862745 0.96862745]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  ...\n",
      "  [1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  [0.96862745 0.96862745 0.96862745]]\n",
      "\n",
      " [[1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  ...\n",
      "  [1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  [0.97254902 0.97254902 0.97254902]]\n",
      "\n",
      " [[1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  ...\n",
      "  [1.         1.         1.        ]\n",
      "  [1.         1.         1.        ]\n",
      "  [0.97254902 0.97254902 0.97254902]]] - Predicted Class: Brown spot\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Predictions\n",
    "test_images = X_test[:5]\n",
    "predictions = model.predict(test_images)\n",
    "\n",
    "for i in range(len(test_images)):\n",
    "    predicted_class_index = np.argmax(predictions[i])\n",
    "    predicted_class = class_names[predicted_class_index]\n",
    "    print(f\"Image: {test_images[i]} - Predicted Class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd91723",
   "metadata": {},
   "source": [
    "## Improve model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bb947293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0210c5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Preparation\n",
    "data_dir = r'C:\\\\Users\\\\bdiko\\\\Downloads\\\\PRCP-1001-RiceLeaf-10\\\\Data\\\\'\n",
    "class_names = ['Bacterial leaf blight', 'Brown spot', 'Leaf smut']\n",
    "image_size = (224, 224)  # Adjust the size according to your requirements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "df3d5caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Data Preprocessing\n",
    "def preprocess_images(images):\n",
    "    processed_images = []\n",
    "    for img in images:\n",
    "        img = Image.fromarray((img * 255).astype(np.uint8))\n",
    "        img = img.resize(image_size)\n",
    "        img = np.array(img) / 255.0  # Normalize pixel values\n",
    "        processed_images.append(img)\n",
    "    return np.array(processed_images)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for class_name in class_names:\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    image_paths = [os.path.join(class_dir, img) for img in os.listdir(class_dir) if img.endswith('.jpg')]\n",
    "    labels = [class_names.index(class_name)] * len(image_paths)\n",
    "    X.extend(image_paths)\n",
    "    y.extend(labels)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f4115ba0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert X_train and X_test to numpy arrays\n",
    "X_train = preprocess_images(X_train)\n",
    "X_test = preprocess_images(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e2c8a863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_train and y_test to numpy arrays\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3b4c1d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Model Development\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(image_size[0], image_size[1], 3))\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(class_names), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aa2f67cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 19s 13s/step - loss: 5.5921 - accuracy: 0.4878 - val_loss: 1.1378 - val_accuracy: 0.3636\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 17s 13s/step - loss: 3.1331 - accuracy: 0.4146 - val_loss: 1.0667 - val_accuracy: 0.3636\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 17s 5s/step - loss: 1.0603 - accuracy: 0.4146 - val_loss: 1.0538 - val_accuracy: 0.3636\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 17s 5s/step - loss: 0.8726 - accuracy: 0.5854 - val_loss: 1.2166 - val_accuracy: 0.3636\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 18s 14s/step - loss: 1.2686 - accuracy: 0.3415 - val_loss: 1.1045 - val_accuracy: 0.4545\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 18s 14s/step - loss: 1.1722 - accuracy: 0.2927 - val_loss: 1.1122 - val_accuracy: 0.4545\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 18s 5s/step - loss: 1.2156 - accuracy: 0.3171 - val_loss: 1.0924 - val_accuracy: 0.4545\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 18s 14s/step - loss: 0.9696 - accuracy: 0.3902 - val_loss: 1.1286 - val_accuracy: 0.3636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x200695cd7b0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Model Training\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "train_datagen = ImageDataGenerator(rotation_range=20, width_shift_range=0.2, height_shift_range=0.2,\n",
    "                                   horizontal_flip=True, shear_range=0.2, zoom_range=0.2)\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "\n",
    "# Early stopping callback to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "model.fit(train_generator, epochs=epochs, validation_data=(X_test, y_test), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "088ef962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 472ms/step\n",
      "Image: [[[0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  ...\n",
      "  [0.1372549  0.14901961 0.79215686]\n",
      "  [0.13333333 0.14509804 0.76862745]\n",
      "  [0.1372549  0.14901961 0.75686275]]\n",
      "\n",
      " [[0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  ...\n",
      "  [0.14901961 0.16078431 0.80392157]\n",
      "  [0.14509804 0.15686275 0.78039216]\n",
      "  [0.14901961 0.16078431 0.76862745]]\n",
      "\n",
      " [[0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  ...\n",
      "  [0.17647059 0.18823529 0.83921569]\n",
      "  [0.17254902 0.18431373 0.81176471]\n",
      "  [0.17647059 0.18823529 0.80392157]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.23529412 0.40784314 0.74901961]\n",
      "  [0.22352941 0.4        0.7372549 ]\n",
      "  [0.21568627 0.38823529 0.73333333]\n",
      "  ...\n",
      "  [0.60392157 0.60784314 1.        ]\n",
      "  [0.59607843 0.6        1.        ]\n",
      "  [0.58431373 0.6        1.        ]]\n",
      "\n",
      " [[0.25490196 0.41960784 0.76078431]\n",
      "  [0.24313725 0.41568627 0.74901961]\n",
      "  [0.23137255 0.40392157 0.74509804]\n",
      "  ...\n",
      "  [0.61176471 0.60784314 0.99215686]\n",
      "  [0.6        0.6        0.98823529]\n",
      "  [0.58039216 0.58823529 0.98039216]]\n",
      "\n",
      " [[0.2627451  0.42745098 0.76470588]\n",
      "  [0.25098039 0.42352941 0.75686275]\n",
      "  [0.23921569 0.41176471 0.74901961]\n",
      "  ...\n",
      "  [0.61176471 0.60784314 0.98431373]\n",
      "  [0.6        0.6        0.98039216]\n",
      "  [0.58039216 0.58823529 0.97254902]]] - Predicted Class: Brown spot\n",
      "Image: [[[0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  ...\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00784314 0.00784314 0.00784314]]\n",
      "\n",
      " [[0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  ...\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00784314 0.00784314 0.00784314]]\n",
      "\n",
      " [[0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  ...\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00784314 0.00784314 0.00784314]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.03921569 0.03921569 0.03921569]\n",
      "  [0.04705882 0.04705882 0.04705882]\n",
      "  [0.03921569 0.03921569 0.03921569]\n",
      "  ...\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]]\n",
      "\n",
      " [[0.03921569 0.03921569 0.03921569]\n",
      "  [0.04705882 0.04705882 0.04705882]\n",
      "  [0.03529412 0.03529412 0.03529412]\n",
      "  ...\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]]\n",
      "\n",
      " [[0.03921569 0.03921569 0.03921569]\n",
      "  [0.04705882 0.04705882 0.04705882]\n",
      "  [0.03529412 0.03529412 0.03529412]\n",
      "  ...\n",
      "  [0.00784314 0.00784314 0.00784314]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]]] - Predicted Class: Brown spot\n",
      "Image: [[[0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  ...\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]]\n",
      "\n",
      " [[0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  ...\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]]\n",
      "\n",
      " [[0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  ...\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  ...\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]]\n",
      "\n",
      " [[0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  ...\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]]\n",
      "\n",
      " [[0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  ...\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]]] - Predicted Class: Brown spot\n",
      "Image: [[[0.30196078 0.15686275 0.75294118]\n",
      "  [0.2745098  0.1254902  0.77647059]\n",
      "  [0.2745098  0.11372549 0.77647059]\n",
      "  ...\n",
      "  [0.39607843 0.19607843 0.8745098 ]\n",
      "  [0.39607843 0.20784314 0.88235294]\n",
      "  [0.39215686 0.21960784 0.88235294]]\n",
      "\n",
      " [[0.39215686 0.23137255 0.84313725]\n",
      "  [0.37254902 0.21176471 0.86666667]\n",
      "  [0.36470588 0.19215686 0.8627451 ]\n",
      "  ...\n",
      "  [0.37647059 0.18039216 0.85098039]\n",
      "  [0.37647059 0.18823529 0.85098039]\n",
      "  [0.38039216 0.20784314 0.86666667]]\n",
      "\n",
      " [[0.37647059 0.19607843 0.83137255]\n",
      "  [0.35686275 0.18039216 0.85098039]\n",
      "  [0.34901961 0.16470588 0.84705882]\n",
      "  ...\n",
      "  [0.34509804 0.15294118 0.81176471]\n",
      "  [0.34901961 0.16862745 0.81960784]\n",
      "  [0.34901961 0.17647059 0.82745098]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  ...\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]]\n",
      "\n",
      " [[0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  ...\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]]\n",
      "\n",
      " [[0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  ...\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]]] - Predicted Class: Brown spot\n",
      "Image: [[[0.03921569 0.03921569 0.03921569]\n",
      "  [0.06666667 0.06666667 0.06666667]\n",
      "  [0.05098039 0.05098039 0.05098039]\n",
      "  ...\n",
      "  [0.03137255 0.03137255 0.03137255]\n",
      "  [0.03137255 0.03137255 0.03137255]\n",
      "  [0.03529412 0.03529412 0.04313725]]\n",
      "\n",
      " [[0.03529412 0.03529412 0.03529412]\n",
      "  [0.05098039 0.05098039 0.05098039]\n",
      "  [0.04705882 0.04705882 0.04705882]\n",
      "  ...\n",
      "  [0.03137255 0.03137255 0.03137255]\n",
      "  [0.03137255 0.03137255 0.03137255]\n",
      "  [0.03529412 0.03529412 0.03921569]]\n",
      "\n",
      " [[0.03529412 0.03529412 0.03529412]\n",
      "  [0.03921569 0.03921569 0.03921569]\n",
      "  [0.03529412 0.03529412 0.03529412]\n",
      "  ...\n",
      "  [0.03529412 0.03529412 0.03529412]\n",
      "  [0.03529412 0.03529412 0.03529412]\n",
      "  [0.03529412 0.03529412 0.03529412]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  ...\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.03529412 0.03529412 0.03529412]]\n",
      "\n",
      " [[0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  ...\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.03137255 0.03137255 0.03137255]]\n",
      "\n",
      " [[0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  ...\n",
      "  [0.00392157 0.00392157 0.00392157]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.03137255 0.03137255 0.03137255]]] - Predicted Class: Brown spot\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Predictions\n",
    "test_images = X_test[:5]\n",
    "preprocessed_test_images = preprocess_images(test_images)\n",
    "predictions = model.predict(preprocessed_test_images)\n",
    "\n",
    "for i, image_path in enumerate(test_images):\n",
    "    predicted_class_index = np.argmax(predictions[i])\n",
    "    predicted_class = class_names[predicted_class_index]\n",
    "    print(f\"Image: {image_path} - Predicted Class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c9446700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 845ms/step\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "Bacterial leaf blight       0.00      0.00      0.00         2\n",
      "           Brown spot       0.36      1.00      0.53         4\n",
      "            Leaf smut       0.00      0.00      0.00         5\n",
      "\n",
      "             accuracy                           0.36        11\n",
      "            macro avg       0.12      0.33      0.18        11\n",
      "         weighted avg       0.13      0.36      0.19        11\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_test, y_pred, target_names=class_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ed2568e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 891ms/step - loss: 1.0538 - accuracy: 0.3636\n",
      "Test Loss: 1.0538\n",
      "Test Accuracy: 0.3636\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d8afe6",
   "metadata": {},
   "source": [
    "### Data augmentation: Apply more aggressive data augmentation techniques to further increase the diversity of your training data. Experiment with a wider range of transformations, such as random rotations, shearing, scaling, and flipping. This can help the model learn more robust features and improve its ability to generalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ee248098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Preparation\n",
    "data_dir =  r'C:\\\\Users\\\\bdiko\\\\Downloads\\\\PRCP-1001-RiceLeaf-10\\\\Data\\\\'\n",
    "class_names = ['Bacterial leaf blight', 'Brown spot', 'Leaf smut']\n",
    "image_size = (224, 224)  # Adjust the size according to your requirements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9296b04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Data Preprocessing\n",
    "def preprocess_images(images):\n",
    "    processed_images = []\n",
    "    for img in images:\n",
    "        img = Image.fromarray((img * 255).astype(np.uint8))\n",
    "        img = img.resize(image_size)\n",
    "        img = np.array(img) / 255.0  # Normalize pixel values\n",
    "        processed_images.append(img)\n",
    "    return np.array(processed_images)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for class_name in class_names:\n",
    "    class_dir = os.path.join(data_dir, class_name.lower())  # Convert to lowercase\n",
    "    image_paths = [os.path.join(class_dir, img) for img in os.listdir(class_dir) if img.endswith('.jpg')]\n",
    "    labels = [class_names.index(class_name)] * len(image_paths)\n",
    "    X.extend(image_paths)\n",
    "    y.extend(labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dc6aeaf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bdiko\\AppData\\Local\\Temp\\ipykernel_9024\\1264991613.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_train = preprocess_images(np.array([np.array(Image.open(fname)) for fname in X_train]))\n",
      "C:\\Users\\bdiko\\AppData\\Local\\Temp\\ipykernel_9024\\1264991613.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_test = preprocess_images(np.array([np.array(Image.open(fname)) for fname in X_test]))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert X_train and X_test to numpy arrays\n",
    "X_train = preprocess_images(np.array([np.array(Image.open(fname)) for fname in X_train]))\n",
    "X_test = preprocess_images(np.array([np.array(Image.open(fname)) for fname in X_test]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9a91b9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert y_train and y_test to numpy arrays\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d7e730c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Model Development\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(image_size[0], image_size[1], 3))\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(class_names), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "eb186970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 19s 14s/step - loss: 35.4557 - accuracy: 0.4146 - val_loss: 1.0892 - val_accuracy: 0.3636\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 18s 5s/step - loss: 1.1313 - accuracy: 0.2927 - val_loss: 1.3416 - val_accuracy: 0.4545\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 18s 5s/step - loss: 1.4481 - accuracy: 0.3659 - val_loss: 1.0359 - val_accuracy: 0.4545\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 18s 14s/step - loss: 0.9868 - accuracy: 0.4634 - val_loss: 1.0449 - val_accuracy: 0.4545\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 18s 14s/step - loss: 1.0819 - accuracy: 0.3902 - val_loss: 1.0436 - val_accuracy: 0.3636\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 18s 5s/step - loss: 0.9666 - accuracy: 0.5366 - val_loss: 1.0552 - val_accuracy: 0.3636\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 18s 14s/step - loss: 0.9809 - accuracy: 0.5366 - val_loss: 1.0536 - val_accuracy: 0.3636\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 18s 14s/step - loss: 0.9947 - accuracy: 0.4634 - val_loss: 1.0706 - val_accuracy: 0.3636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x200031cfcd0>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Model Training\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "model.fit(train_generator, epochs=epochs, validation_data=(X_test, y_test), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "39feaf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 1.0359 - accuracy: 0.4545\n",
      "Test Loss: 1.0359\n",
      "Test Accuracy: 0.4545\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Evaluation\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072dba8a",
   "metadata": {},
   "source": [
    "It seems that the accuracy of the model on the test set is 45.45%. This result indicates that the model is not performing well and may require further improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a269ed",
   "metadata": {},
   "source": [
    "## Adjust hyperparameters: Experiment with different hyperparameters, such as learning rate, batch size, and optimizer. You can try decreasing the learning rate, increasing the batch size, or using a different optimizer to see if it improves the model's performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "22eea09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 19s 19s/step - loss: 1.0550 - accuracy: 0.3415 - val_loss: 1.1165 - val_accuracy: 0.3636\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 17s 17s/step - loss: 0.9786 - accuracy: 0.4878 - val_loss: 9.0743 - val_accuracy: 0.4545\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 18s 18s/step - loss: 9.6802 - accuracy: 0.4390 - val_loss: 1.0555 - val_accuracy: 0.3636\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 17s 17s/step - loss: 1.0435 - accuracy: 0.3171 - val_loss: 1.0560 - val_accuracy: 0.3636\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 18s 18s/step - loss: 0.9394 - accuracy: 0.4878 - val_loss: 1.0484 - val_accuracy: 0.3636\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 18s 18s/step - loss: 0.9849 - accuracy: 0.5366 - val_loss: 1.0731 - val_accuracy: 0.3636\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 19s 19s/step - loss: 1.0016 - accuracy: 0.4390 - val_loss: 1.0354 - val_accuracy: 0.3636\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 18s 18s/step - loss: 1.0321 - accuracy: 0.4146 - val_loss: 1.2559 - val_accuracy: 0.4545\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 18s 18s/step - loss: 1.6986 - accuracy: 0.3171 - val_loss: 1.0462 - val_accuracy: 0.3636\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 18s 18s/step - loss: 0.9598 - accuracy: 0.3902 - val_loss: 1.1720 - val_accuracy: 0.3636\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 19s 19s/step - loss: 0.9997 - accuracy: 0.4878 - val_loss: 1.2645 - val_accuracy: 0.3636\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 19s 19s/step - loss: 1.0805 - accuracy: 0.4634 - val_loss: 1.0886 - val_accuracy: 0.3636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20007c2fee0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Model Training\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "\n",
    "optimizer = Adam(lr=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "model.fit(train_generator, epochs=epochs, validation_data=(X_test, y_test), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "56f64b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 924ms/step - loss: 1.0354 - accuracy: 0.3636\n",
      "Test Loss: 1.0354\n",
      "Test Accuracy: 0.3636\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324550a4",
   "metadata": {},
   "source": [
    "## Ensemble learning involves combining multiple models to improve performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "03cd0666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3e82124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base models\n",
    "model1 = SVC(kernel='rbf', probability=True)\n",
    "model2 = RandomForestClassifier(n_estimators=100)\n",
    "model3 = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b8aa842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ensemble model\n",
    "ensemble_model = VotingClassifier(estimators=[('svm', model1), ('rf', model2), ('lr', model3)], voting='soft')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5ef608ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the input data\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "73bb7d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;svm&#x27;, SVC(probability=True)),\n",
       "                             (&#x27;rf&#x27;, RandomForestClassifier()),\n",
       "                             (&#x27;lr&#x27;, LogisticRegression())],\n",
       "                 voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;svm&#x27;, SVC(probability=True)),\n",
       "                             (&#x27;rf&#x27;, RandomForestClassifier()),\n",
       "                             (&#x27;lr&#x27;, LogisticRegression())],\n",
       "                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>svm</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(probability=True)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('svm', SVC(probability=True)),\n",
       "                             ('rf', RandomForestClassifier()),\n",
       "                             ('lr', LogisticRegression())],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the ensemble model\n",
    "ensemble_model.fit(X_train_reshaped, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fb4ff5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Accuracy: 0.7273\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the ensemble model\n",
    "accuracy = ensemble_model.score(X_test_reshaped, y_test)\n",
    "print(f\"Ensemble Model Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3d600c",
   "metadata": {},
   "source": [
    "It looks like the ensemble model with the reshaped input data has achieved an accuracy of 0.7273. This indicates an improvement over the previous model.\n",
    "\n",
    "Ensemble learning can often help improve the model's performance by leveraging the strengths of multiple models. In this case, combining different classifiers using a voting scheme has resulted in better accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb937cb",
   "metadata": {},
   "source": [
    "## cross-validation and grid search to tune the hyperparameters of your ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "412c4ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8d1982a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'svm__C': [0.1, 1, 10],\n",
    "    'rf__n_estimators': [100, 200, 300],\n",
    "    'lr__C': [0.1, 1, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e9cc304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=ensemble_model, param_grid=param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "dc67b897",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bdiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=VotingClassifier(estimators=[(&#x27;svm&#x27;,\n",
       "                                                     SVC(probability=True)),\n",
       "                                                    (&#x27;rf&#x27;,\n",
       "                                                     RandomForestClassifier()),\n",
       "                                                    (&#x27;lr&#x27;,\n",
       "                                                     LogisticRegression())],\n",
       "                                        voting=&#x27;soft&#x27;),\n",
       "             param_grid={&#x27;lr__C&#x27;: [0.1, 1, 10],\n",
       "                         &#x27;rf__n_estimators&#x27;: [100, 200, 300],\n",
       "                         &#x27;svm__C&#x27;: [0.1, 1, 10]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=VotingClassifier(estimators=[(&#x27;svm&#x27;,\n",
       "                                                     SVC(probability=True)),\n",
       "                                                    (&#x27;rf&#x27;,\n",
       "                                                     RandomForestClassifier()),\n",
       "                                                    (&#x27;lr&#x27;,\n",
       "                                                     LogisticRegression())],\n",
       "                                        voting=&#x27;soft&#x27;),\n",
       "             param_grid={&#x27;lr__C&#x27;: [0.1, 1, 10],\n",
       "                         &#x27;rf__n_estimators&#x27;: [100, 200, 300],\n",
       "                         &#x27;svm__C&#x27;: [0.1, 1, 10]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;svm&#x27;, SVC(probability=True)),\n",
       "                             (&#x27;rf&#x27;, RandomForestClassifier()),\n",
       "                             (&#x27;lr&#x27;, LogisticRegression())],\n",
       "                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>svm</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(probability=True)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=VotingClassifier(estimators=[('svm',\n",
       "                                                     SVC(probability=True)),\n",
       "                                                    ('rf',\n",
       "                                                     RandomForestClassifier()),\n",
       "                                                    ('lr',\n",
       "                                                     LogisticRegression())],\n",
       "                                        voting='soft'),\n",
       "             param_grid={'lr__C': [0.1, 1, 10],\n",
       "                         'rf__n_estimators': [100, 200, 300],\n",
       "                         'svm__C': [0.1, 1, 10]})"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train_reshaped, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c7b3fa44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'lr__C': 0.1, 'rf__n_estimators': 100, 'svm__C': 0.1}\n",
      "Best Score: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9d3337af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Accuracy: 0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the ensemble model with the best parameters\n",
    "accuracy = grid_search.score(X_test_reshaped, y_test)\n",
    "print(\"Ensemble Model Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3126c9aa",
   "metadata": {},
   "source": [
    "Accuracy is near the same using ensemble model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4307e887",
   "metadata": {},
   "source": [
    "## Lets try Transfer learning. \n",
    "- It is a powerful technique that allows you to leverage pre-trained models to improve the performance of your specific task. We applied transfer learning using a pre-trained modelVGG16, ResNet50 and InceptionV3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "6585f809",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16, ResNet50, InceptionV3\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "55dd3d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5bedcb",
   "metadata": {},
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "890ffc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the pre-trained model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "# base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "# base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "4c332eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the layers of the pre-trained model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "02d04a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model and add the pre-trained base model\n",
    "model = Sequential()\n",
    "model.add(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "c748d169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your own classification layers on top\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "8c84177c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "ab982a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x0000020043239870> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x0000020043239870> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 11s 4s/step - loss: 1.3890 - accuracy: 1.0000 - val_loss: 0.7201 - val_accuracy: 0.3333\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 11s 4s/step - loss: 1.3916 - accuracy: 1.0000 - val_loss: 0.7200 - val_accuracy: 0.3333\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 11s 4s/step - loss: 1.3915 - accuracy: 1.0000 - val_loss: 0.7198 - val_accuracy: 0.3333\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 12s 4s/step - loss: 1.3915 - accuracy: 1.0000 - val_loss: 0.7195 - val_accuracy: 0.3333\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 12s 4s/step - loss: 1.3914 - accuracy: 1.0000 - val_loss: 0.7193 - val_accuracy: 0.3333\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 13s 5s/step - loss: 1.3913 - accuracy: 1.0000 - val_loss: 0.7191 - val_accuracy: 0.3333\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 12s 4s/step - loss: 1.3912 - accuracy: 1.0000 - val_loss: 0.7189 - val_accuracy: 0.3333\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 13s 5s/step - loss: 1.3912 - accuracy: 1.0000 - val_loss: 0.7187 - val_accuracy: 0.3333\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 12s 4s/step - loss: 1.3911 - accuracy: 1.0000 - val_loss: 0.7185 - val_accuracy: 0.3333\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 12s 4s/step - loss: 1.3910 - accuracy: 1.0000 - val_loss: 0.7184 - val_accuracy: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x200432939d0>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_generator, epochs=10, validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "4873fd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.7184 - accuracy: 0.3333\n",
      "Test Loss: 0.7183578014373779\n",
      "Test Accuracy: 0.3333333432674408\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(test_generator, verbose=1)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed07ac4",
   "metadata": {},
   "source": [
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "c66f64f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 18s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Choose the pre-trained model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "53e2115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the layers of the pre-trained model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "bda4f8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model and add the pre-trained base model\n",
    "model = Sequential()\n",
    "model.add(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "260cb811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your own classification layers on top\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "a66ff2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "308b41f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 11s 3s/step - loss: 3.7806 - accuracy: 0.3263 - val_loss: 0.7049 - val_accuracy: 0.2917\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 7s 3s/step - loss: 2.2072 - accuracy: 0.9579 - val_loss: 1.4393 - val_accuracy: 0.3333\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 7s 3s/step - loss: 1.7377 - accuracy: 0.6737 - val_loss: 0.6770 - val_accuracy: 0.6667\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 8s 2s/step - loss: 1.7669 - accuracy: 0.0000e+00 - val_loss: 0.6470 - val_accuracy: 0.6667\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 8s 3s/step - loss: 1.4632 - accuracy: 0.6632 - val_loss: 0.9962 - val_accuracy: 0.3333\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 8s 3s/step - loss: 1.5798 - accuracy: 1.0000 - val_loss: 0.7319 - val_accuracy: 0.3333\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 8s 3s/step - loss: 1.4142 - accuracy: 0.3368 - val_loss: 0.6337 - val_accuracy: 0.6667\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 8s 3s/step - loss: 1.4438 - accuracy: 0.0000e+00 - val_loss: 0.7049 - val_accuracy: 0.2500\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 8s 3s/step - loss: 1.4220 - accuracy: 0.9684 - val_loss: 0.8143 - val_accuracy: 0.3333\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 8s 3s/step - loss: 1.4244 - accuracy: 1.0000 - val_loss: 0.6804 - val_accuracy: 0.7083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20043943340>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_generator, epochs=10, validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "2e2f13e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.6804 - accuracy: 0.7083\n",
      "Test Loss: 0.680443286895752\n",
      "Test Accuracy: 0.7083333134651184\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(test_generator, verbose=1)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f64cdb",
   "metadata": {},
   "source": [
    "## InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "ed1c6280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87910968/87910968 [==============================] - 16s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Choose the pre-trained model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "fc519e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the layers of the pre-trained model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "57c3afc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model and add the pre-trained base model\n",
    "model = Sequential()\n",
    "model.add(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "020ca262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your own classification layers on top\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "209be51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "7856f5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 9s 2s/step - loss: 2.9167 - accuracy: 0.4526 - val_loss: 1.1683 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 2.1997 - accuracy: 0.6632 - val_loss: 0.6445 - val_accuracy: 0.5833\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 1.9716 - accuracy: 0.5263 - val_loss: 0.9650 - val_accuracy: 0.5417\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 1.6226 - accuracy: 0.2947 - val_loss: 1.0364 - val_accuracy: 0.5417\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 1.6758 - accuracy: 0.8526 - val_loss: 0.7724 - val_accuracy: 0.6667\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 1.6441 - accuracy: 0.3579 - val_loss: 1.3412 - val_accuracy: 0.2917\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 1.7272 - accuracy: 0.6105 - val_loss: 0.8437 - val_accuracy: 0.6250\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 1.6687 - accuracy: 0.6316 - val_loss: 0.9687 - val_accuracy: 0.4167\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 1.5140 - accuracy: 0.3053 - val_loss: 1.0900 - val_accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 1.5263 - accuracy: 0.8000 - val_loss: 0.7465 - val_accuracy: 0.5833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20027eb7ee0>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_generator, epochs=10, validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "ddf5f3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 982ms/step - loss: 0.7465 - accuracy: 0.5833\n",
      "Test Loss: 0.7464776039123535\n",
      "Test Accuracy: 0.5833333134651184\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(test_generator, verbose=1)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8bd40f",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "### Ensemble Model Accuracy of 0.7273 is the highest one suggesting that this is the best model to be used for Rice Leaf Disease detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299e06e9",
   "metadata": {},
   "source": [
    "Ensemble modeling is a technique that combines multiple individual models to make predictions. It has been widely used in machine learning to improve prediction accuracy and reduce model bias. Although the individual models may have slightly lower accuracy compared to the ensemble model, the ensemble approach can often yield better overall performance.\n",
    "\n",
    "Here are a few reasons why ensemble modeling can be beneficial:\n",
    "\n",
    "Improved Generalization: Ensemble models can reduce the risk of overfitting, which occurs when a model learns too much from the training data and performs poorly on unseen data. By combining multiple models that have been trained on different subsets of the data or using different algorithms, ensemble models can capture a broader range of patterns and make more robust predictions on unseen data.\n",
    "\n",
    "Increased Stability: Ensemble models tend to be more stable than individual models. Even if some of the individual models in the ensemble make incorrect predictions, the combined predictions of all the models can still provide accurate results. This stability is especially useful when dealing with noisy or uncertain data.\n",
    "\n",
    "Reduction of Bias: Different models may have different biases due to variations in their architectures, training data, or algorithms. By combining models with diverse biases, ensemble models can mitigate the individual biases and provide a more balanced prediction.\n",
    "\n",
    "Error Correction: Ensemble models can correct errors made by individual models. If one model misclassifies a sample, other models in the ensemble can potentially correct that mistake, leading to more accurate predictions overall.\n",
    "\n",
    "Better Performance on Unseen Data: Ensemble models often exhibit better performance on unseen data compared to individual models. By leveraging the collective knowledge and predictions of multiple models, ensemble models can achieve higher accuracy, robustness, and generalization capability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875fef7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
